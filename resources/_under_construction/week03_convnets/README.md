__Note__: Seminars assume that you remember batch normalization and dropout from last lecture. If you don't, go recap week2.

## Materials
- [russian] Convolutional networks - [video](https://yadi.sk/i/hDIkaR4H3EtnXM)
- [english] Convolutional networks (karpathy) - [video](https://www.youtube.com/watch?v=AQirPKrAyDg)

- Reading
  - http://cs231n.github.io/convolutional-networks/
  - http://cs231n.github.io/understanding-cnn/
  - [a deep learning neophite cheat sheet](http://www.kdnuggets.com/2016/03/must-know-tips-deep-learning-part-1.html)
  - [more stuff for vision](https://bavm2013.splashthat.com/img/events/46439/assets/34a7.ranzato.pdf)
  - a [CNN trainer in a browser](https://cs.stanford.edu/people/karpathy/convnetjs/demo/cifar10.html)
  - Bonus: [graph convolutions](https://colab.research.google.com/drive/155nh8rZ63C7EWBNhbSJzYdab92hPHMTH)

## Assignment

[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/yandexdataschool/Practical_DL/blob/spring2019/week03_convnets/seminar_pytorch.ipynb)

As usual, go to seminar_pytorch.ipynb and folow instructons from there.

There's also ./other_frameworks if you're more into theano/tf.
