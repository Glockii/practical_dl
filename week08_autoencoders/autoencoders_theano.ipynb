{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Denoising Autoencoders And Where To Find Them\n",
    "\n",
    "Today we're going to train deep autoencoders and deploy them to faces and search for similar images.\n",
    "\n",
    "Our new test subjects are human faces from the [lfw dataset](http://vis-www.cs.umass.edu/lfw/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from lfw_dataset import fetch_lfw_dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "X, attr = fetch_lfw_dataset(use_raw=True,dimx=38,dimy=38)\n",
    "X = X.transpose([0,3,1,2]).astype('float32') / 256.0\n",
    "\n",
    "img_shape = X.shape[1:]\n",
    "print(\"Image shape:\",img_shape)\n",
    "\n",
    "X_train, X_test = train_test_split(X, test_size=0.1,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.title('sample image')\n",
    "for i in range(6):\n",
    "    plt.subplot(2,3,i+1)\n",
    "    plt.imshow(X[i].transpose([1,2,0]))\n",
    "\n",
    "print(\"X shape:\",X.shape)\n",
    "print(\"attr shape:\",attr.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Autoencoder architecture\n",
    "\n",
    "Let's design autoencoder as a single lasagne network, going from input image through bottleneck into the reconstructed image.\n",
    "\n",
    "<img src=\"http://nghiaho.com/wp-content/uploads/2012/12/autoencoder_network1.png\" width=640px>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First step: PCA\n",
    "\n",
    "Principial Component Analysis is a popular dimensionality reduction method. \n",
    "\n",
    "Under the hood, PCA attempts to decompose object-feature matrix $X$ into two smaller matrices: $W$ and $\\hat W$ minimizing _mean squared error_:\n",
    "\n",
    "$$\\|(X W) \\hat{W} - X\\|^2_2 \\to_{W, \\hat{W}} \\min$$\n",
    "- $X \\in \\mathbb{R}^{n \\times m}$ - object matrix (**centered**);\n",
    "- $W \\in \\mathbb{R}^{m \\times d}$ - matrix of direct transformation;\n",
    "- $\\hat{W} \\in \\mathbb{R}^{d \\times m}$ - matrix of reverse transformation;\n",
    "- $n$ samples, $m$ original dimensions and $d$ target dimensions;\n",
    "\n",
    "In geometric terms, we want to find d axes along which most of variance occurs. The \"natural\" axes, if you wish.\n",
    "\n",
    "![](https://upload.wikimedia.org/wikipedia/commons/thumb/9/90/PCA_fish.png/256px-PCA_fish.png)\n",
    "\n",
    "\n",
    "PCA can also be seen as a special case of an autoencoder.\n",
    "\n",
    "* __Encoder__: X -> Dense(d units) -> code\n",
    "* __Decoder__: code -> Dense(m units) -> X\n",
    "\n",
    "Where Dense is a fully-connected layer with linear activaton:   $f(X) = W \\cdot X + \\vec b $\n",
    "\n",
    "\n",
    "Note: the bias term in those layers is responsible for \"centering\" the matrix i.e. substracting mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import theano,theano.tensor as T\n",
    "import lasagne,lasagne.layers as L\n",
    "def build_pca_autoencoder(img_shape,code_size=32):\n",
    "    \"\"\"\n",
    "    Here we define a simple linear autoencoder as described above.\n",
    "    We also reshape decoded data to be compatible with image shapes\n",
    "    \"\"\"\n",
    "    inp = L.InputLayer((None,)+img_shape)\n",
    "    enc = L.DenseLayer(inp,code_size,nonlinearity=None)\n",
    "    \n",
    "    dec = L.DenseLayer(enc,np.prod(img_shape),nonlinearity=None)  #actual decoder, height*width*3 units\n",
    "    dec = L.ReshapeLayer(dec,(-1,)+img_shape)\n",
    "    \n",
    "    return inp,enc,dec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Meld them together into one model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp, encoder, decoder = build_pca_autoencoder(img_shape,code_size=32)\n",
    "\n",
    "code,reconstruction = L.get_output([encoder,decoder])\n",
    "loss = T.mean((inp.input_var - reconstruction)**2)\n",
    "updates = lasagne.updates.adamax(loss,L.get_all_params(decoder,trainable=True))\n",
    "\n",
    "train_step = theano.function([inp.input_var],loss,updates=updates,allow_input_downcast=True)\n",
    "compute_loss = theano.function([inp.input_var],loss,allow_input_downcast=True)\n",
    "encode_decode = theano.function([inp.input_var],[code,reconstruction],allow_input_downcast=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model\n",
    "\n",
    "As usual, iterate minibatches of data and call train_step, then evaluate loss on validation data.\n",
    "\n",
    "__Note to py2 users:__ you can safely drop `flush=True` from any code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import sys\n",
    "def iterate_minibatches(data, batch_size = 32,verbose = True):\n",
    "    indices = np.random.permutation(np.arange(len(data)))\n",
    "    batches = range(0, len(data), batch_size)\n",
    "    if verbose: \n",
    "        batches = tqdm(batches)\n",
    "    return (data[indices[start_idx:start_idx + batch_size]] for start_idx in batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for epoch in range(32):\n",
    "    losses = []\n",
    "    for x_batch in iterate_minibatches(X_train,batch_size=50):\n",
    "        losses.append(train_step(x_batch))\n",
    "    print(\"#%i, Train loss: %.7f\"%(epoch+1,np.mean(losses)),flush=True)\n",
    "    \n",
    "    val_losses = list(map(compute_loss,iterate_minibatches(X_test,verbose=False)))\n",
    "    print(\"#%i, Test loss: %.7f\"%(epoch+1,np.mean(val_losses)),flush=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def visualize(img,encoder,decoder):\n",
    "    \"\"\"Draws original, encoded and decoded images\"\"\"\n",
    "    code,reco = encode_decode(img[None])\n",
    "\n",
    "    plt.subplot(1,3,1)\n",
    "    plt.title(\"Original\")\n",
    "    plt.imshow(img.transpose([1,2,0]))\n",
    "\n",
    "    plt.subplot(1,3,2)\n",
    "    plt.title(\"Code\")\n",
    "    plt.imshow(code.reshape([code.shape[-1]//2,-1]))\n",
    "\n",
    "    plt.subplot(1,3,3)\n",
    "    plt.title(\"Reconstructed\")\n",
    "    plt.imshow(reco[0].transpose([1,2,0]).clip(0,1))\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = np.mean(list(map(compute_loss,iterate_minibatches(X_test,verbose=False))))\n",
    "print(\"Final MSE:\",score)\n",
    "\n",
    "for i in range(5):\n",
    "    img = X_test[i]\n",
    "    visualize(img,encoder,decoder)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Going deeper\n",
    "\n",
    "PCA is neat but surely we can do better. This time we want you to build a deep autoencoder by... stacking more layers.\n",
    "\n",
    "In particular, your encoder and decoder should be at least 3 layers deep each. You can use any nonlinearity you want and any number of hidden units in non-bottleneck layers provided you can actually afford training it.\n",
    "\n",
    "![layers](https://pbs.twimg.com/media/CYggEo-VAAACg_n.png:small)\n",
    "\n",
    "A few sanity checks:\n",
    "* There shouldn't be any hidden layer smaller than bottleneck (encoder output).\n",
    "* Don't forget to insert nonlinearities between intermediate dense layers.\n",
    "* Convolutional layers are allowed but not required. To undo convolution use L.Deconv2D, pooling - L.UpSampling2D.\n",
    "* Adding activation after bottleneck is allowed, but not strictly necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_deep_autoencoder(img_shape,code_size=32):\n",
    "    \"\"\"PCA's deeper brother. See instructions above\"\"\"\n",
    "    C,H,W = img_shape\n",
    "    \n",
    "    inp = L.InputLayer((None,)+img_shape)\n",
    "    \n",
    "    <Your code: define encoder as per instructions above>\n",
    "    encoder = <...>\n",
    "    \n",
    "    <Your code: define encoder as per instructions above>\n",
    "    decoder = <...>\n",
    "    \n",
    "    return inp,encoder,decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check autoencoder shapes along different code_sizes\n",
    "get_dim = lambda layer: np.prod(layer.output_shape[1:])\n",
    "for code_size in [1,8,32,128,512,1024]:\n",
    "    _,encoder,decoder = build_deep_autoencoder(img_shape,code_size=code_size)\n",
    "    print(\"Testing code size %i\" % code_size)\n",
    "    assert encoder.output_shape[1:]==(code_size,),\"encoder must output a code of required size\"\n",
    "    assert decoder.output_shape[1:]==img_shape,   \"decoder must output an image of valid shape\"\n",
    "    assert len(L.get_all_params(decoder))>=6,       \"encoder must contain at least 3 dense layers\"\n",
    "    \n",
    "    for layer in L.get_all_layers(decoder):\n",
    "        assert get_dim(layer) >= code_size, \"Encoder layer %s is smaller than bottleneck (%i units)\"%(layer.name,get_dim(layer))\n",
    "\n",
    "print(\"All tests passed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Hint:__ if you're getting \"Encoder layer is smaller than bottleneck\" error, use code_size when defining intermediate layers. \n",
    "\n",
    "For example, such layer may have code_size*2 units."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inp, encoder, decoder = build_pca_autoencoder(img_shape,code_size=32)\n",
    "\n",
    "code,reconstruction = L.get_output([encoder,decoder])\n",
    "loss = T.mean((inp.input_var - reconstruction)**2)\n",
    "updates = lasagne.updates.adamax(loss,L.get_all_params(decoder,trainable=True))\n",
    "\n",
    "train_step = theano.function([inp.input_var],loss,updates=updates,allow_input_downcast=True)\n",
    "compute_loss = theano.function([inp.input_var],loss,allow_input_downcast=True)\n",
    "encode_decode = theano.function([inp.input_var],[code,reconstruction],allow_input_downcast=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training may take long, it's okay."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(32):\n",
    "    losses = []\n",
    "    for x_batch in iterate_minibatches(X_train,batch_size=50):\n",
    "        losses.append(train_step(x_batch))\n",
    "    print(\"#%i, Train loss: %.7f\"%(epoch+1,np.mean(losses)),flush=True)\n",
    "    \n",
    "    val_losses = list(map(compute_loss,iterate_minibatches(X_test,verbose=False)))\n",
    "    print(\"#%i, Test loss: %.7f\"%(epoch+1,np.mean(val_losses)),flush=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstruction_mse = np.mean(list(map(compute_loss,iterate_minibatches(X_test,verbose=False))))\n",
    "assert reconstruction_mse <= 0.005, \"Compression is too lossy. See tips below.\"\n",
    "assert len(encoder.output_shape)==2 and encoder.output_shape[1]==32, \"Make sure encoder has code_size units\"\n",
    "print(\"Final MSE:\", reconstruction_mse)\n",
    "for i in range(5):\n",
    "    img = X_test[i]\n",
    "    visualize(img,encoder,decoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Tips:__ If you keep getting \"Compression to lossy\" error, there's a few things you might try:\n",
    "\n",
    "* Make sure it converged. Some architectures need way more than 32 epochs to converge. They may fluctuate a lot, but eventually they're going to get good enough to pass. You may train your network for as long as you want.\n",
    "\n",
    "* Complexity. If you already have, like, 152 layers and still not passing threshold, you may wish to start from something simpler instead and go in small incremental steps.\n",
    "\n",
    "* Architecture. You can use any combination of layers (including convolutions, normalization, etc) as long as __encoder output only stores 32 numbers per training object__. \n",
    "\n",
    "A cunning learner can circumvent this last limitation by using some manual encoding strategy, but he is strongly recommended to avoid that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Denoising AutoEncoder\n",
    "\n",
    "Let's now make our model into a denoising autoencoder.\n",
    "\n",
    "We'll keep your model architecture, but change the way it trains. In particular, we'll corrupt it's input data randomly before each epoch.\n",
    "\n",
    "There are many strategies to apply noise. We'll implement two popular one: adding gaussian noise and using dropout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def apply_gaussian_noise(X,sigma=0.1):\n",
    "    \"\"\"\n",
    "    adds noise from normal distribution with standard deviation sigma\n",
    "    :param X: image tensor of shape [batch,height,width,3]\n",
    "    \"\"\"\n",
    "    \n",
    "    <your code here>\n",
    "        \n",
    "    return X + noise\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#noise tests\n",
    "theoretical_std = (X[:100].std()**2 + 0.5**2)**.5\n",
    "our_std = apply_gaussian_noise(X[:100],sigma=0.5).std()\n",
    "assert abs(theoretical_std - our_std) < 0.01, \"Standard deviation does not match it's required value. Make sure you use sigma as std.\"\n",
    "assert abs(apply_gaussian_noise(X[:100],sigma=0.5).mean() - X[:100].mean()) < 0.01, \"Mean has changed. Please add zero-mean noise\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.subplot(1,4,1)\n",
    "plt.imshow(X[0])\n",
    "plt.subplot(1,4,2)\n",
    "plt.imshow(apply_gaussian_noise(X[:1],sigma=0.01)[0])\n",
    "plt.subplot(1,4,3)\n",
    "plt.imshow(apply_gaussian_noise(X[:1],sigma=0.1)[0])\n",
    "plt.subplot(1,4,4)\n",
    "plt.imshow(apply_gaussian_noise(X[:1],sigma=0.5)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inp, encoder, decoder = build_pca_autoencoder(img_shape,code_size=32)\n",
    "\n",
    "code,reconstruction = L.get_output([encoder,decoder])\n",
    "loss = T.mean((inp.input_var - reconstruction)**2)\n",
    "updates = lasagne.updates.adamax(loss,L.get_all_params(decoder,trainable=True))\n",
    "\n",
    "train_step = theano.function([inp.input_var],loss,updates=updates,allow_input_downcast=True)\n",
    "compute_loss = theano.function([inp.input_var],loss,allow_input_downcast=True)\n",
    "encode_decode = theano.function([inp.input_var],[code,reconstruction],allow_input_downcast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for epoch in range(50):\n",
    "    print(\"Epoch %i/50, Generating corrupted samples...\"%epoch)\n",
    "    X_train_noise = apply_gaussian_noise(X_train)\n",
    "    X_test_noise = apply_gaussian_noise(X_test)\n",
    "    \n",
    "    losses = []\n",
    "    for x_batch in iterate_minibatches(X_train_noise,batch_size=50):\n",
    "        losses.append(train_step(x_batch))\n",
    "    print(\"#%i, Train loss: %.7f\"%(epoch+1,np.mean(losses)),flush=True)\n",
    "    \n",
    "    val_losses = list(map(compute_loss,iterate_minibatches(X_test_noise,verbose=False)))\n",
    "    print(\"#%i, Test loss: %.7f\"%(epoch+1,np.mean(val_losses)),flush=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Note:__ if it hasn't yet converged, increase the number of iterations.\n",
    "\n",
    "__Bonus:__ replace gaussian noise with masking random rectangles on image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reconstruction_mse = np.mean(list(map(compute_loss,iterate_minibatches(X_test,verbose=False))))\n",
    "print(\"Final MSE:\", reconstruction_mse)\n",
    "for i in range(5):\n",
    "    img = X_test[i]\n",
    "    visualize(img,encoder,decoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image retrieval with autoencoders\n",
    "\n",
    "So we've just trained a network that converts image into itself imperfectly. This task is not that useful in and of itself, but it has a number of awesome side-effects. Let's see it in action.\n",
    "\n",
    "First thing we can do is image retrieval aka image search. We we give it an image and find similar images in latent space. \n",
    "\n",
    "To speed up retrieval process, we shall use Locality-Sensitive Hashing on top of encoded vectors. We'll use scikit-learn's implementation for simplicity. In practical scenario, you may want to use [specialized libraries](https://erikbern.com/2015/07/04/benchmark-of-approximate-nearest-neighbor-libraries.html) for better performance and customization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compile function that encodes batch of images into a batch of vector[batch,code_size]\n",
    "encode = theano.function([inp.input_var],code,allow_input_downcast=True)\n",
    "#... and another function that casts those codes back into images\n",
    "codes = T.matrix(\"codes\")\n",
    "decode = theano.function([codes],L.get_output(decoder,{encoder:codes}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = X_train\n",
    "codes = <encode all images>\n",
    "assert len(codes) == len(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import LSHForest\n",
    "lshf = LSHForest(n_estimators=50).fit(codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_similar(image, n_neighbors=5):\n",
    "    assert image.ndim==3,\"image must be [batch,height,width,3]\"\n",
    "\n",
    "    code = <encode image>\n",
    "    \n",
    "    (distances,),(idx,) = lshf.kneighbors(code,n_neighbors=n_neighbors)\n",
    "    \n",
    "    return distances,images[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def show_similar(image):\n",
    "    \n",
    "    distances,neighbors = get_similar(image,n_neighbors=11)\n",
    "    \n",
    "    plt.figure(figsize=[8,6])\n",
    "    plt.subplot(3,4,1)\n",
    "    plt.imshow(image)\n",
    "    plt.title(\"Original image\")\n",
    "    \n",
    "    for i in range(11):\n",
    "        plt.subplot(3,4,i+2)\n",
    "        plt.imshow(neighbors[i])\n",
    "        plt.title(\"Dist=%.3f\"%distances[i])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#smiles\n",
    "show_similar(X_test[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ethnicity\n",
    "show_similar(X_test[500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#glasses\n",
    "show_similar(X_test[66])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Bonus: cheap image morphing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for _ in range(5):\n",
    "    image1,image2 = X_test[np.random.randint(0,len(X_test),size=2)]\n",
    "\n",
    "    code1, code2 = encode(np.stack([image1,image2]))\n",
    "\n",
    "    plt.figure(figsize=[10,4])\n",
    "    for i,a in enumerate(np.linspace(0,1,num=7)):\n",
    "\n",
    "        output_code = code1*(1-a) + code2*(a)\n",
    "        output_image = decode(output_code[None])[0]\n",
    "\n",
    "        plt.subplot(1,7,i+1)\n",
    "        plt.imshow(output_image.transpose([1,2,0]).clip(0,1))\n",
    "        plt.title(\"a=%.2f\"%a)\n",
    "        \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Of course there's a lot more you can do with autoencoders.\n",
    "\n",
    "If you want to generate images from scratch, however, we recommend you our honor track seminar about generative adversarial networks."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
